{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/stroud/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "nltk.download('punkt')\n",
    "\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "d = pd.read_csv('../data/drugsComTrain_raw.tsv', sep='\\t')[:1000]\n",
    "len(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean out broken condition names\n",
    "notspan = d.condition.apply(lambda x: False if type(x)==float else '</span>' not in x)\n",
    "d = d[notspan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    \"It has no side effect, I take it in combinati...\n",
       "1    \"My son is halfway through his fourth week of ...\n",
       "2    \"I used to take another oral contraceptive, wh...\n",
       "3    \"This is my first time using any form of birth...\n",
       "4    \"Suboxone has completely turned my life around...\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at some reviews\n",
    "d.review.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    9.0\n",
       "1    8.0\n",
       "2    5.0\n",
       "3    8.0\n",
       "4    9.0\n",
       "Name: rating, dtype: float64"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And ratings\n",
    "d.rating.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It',\n",
       " 'has',\n",
       " 'no',\n",
       " 'side',\n",
       " 'effect',\n",
       " ',',\n",
       " 'I',\n",
       " 'take',\n",
       " 'it',\n",
       " 'in',\n",
       " 'combination',\n",
       " 'of',\n",
       " 'Bystolic',\n",
       " '5',\n",
       " 'Mg',\n",
       " 'and',\n",
       " 'Fish',\n",
       " 'Oil']"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split each sentence into words, or \"tokens\"\n",
    "d['tokens'] = d.review.apply(word_tokenize).apply(lambda x: x[1:-1])  # shave off quotation marks\n",
    "d.tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I', 5184), ('.', 5067), ('and', 2644), (',', 2557), ('the', 2066), ('to', 1969), (';', 1764), ('&', 1739), ('a', 1684), ('it', 1563)]\n"
     ]
    }
   ],
   "source": [
    "# count up the 100 most common words\n",
    "vocab = Counter()\n",
    "for tokens in d['tokens']:\n",
    "    vocab.update(tokens)\n",
    "vocab_counts = vocab.most_common(100)\n",
    "print(vocab_counts[:10])\n",
    "vocab = [v[0] for v in vocab_counts]  # remove the numbers\n",
    "vocab_dict = {v: i for i, v in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert each sentence binary indicators\n",
    "def tokens2array(tokens):\n",
    "    array = np.zeros((len(vocab),))\n",
    "    for token in tokens:\n",
    "        if token in vocab_dict:\n",
    "            array[vocab_dict[token]] = 1\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['array'] = d['tokens'].apply(tokens2array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr = np.stack(d.array.values)\n",
    "Ytr = np.asarray(d.rating) > 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(984, 100)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(984,)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ytr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sklearn.linear_model.logistic.LogisticRegression(penalty='l1', C=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xtr, Ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.45290057, 0.54709943],\n",
       "       [0.5148556 , 0.4851444 ],\n",
       "       [0.37719083, 0.62280917],\n",
       "       ...,\n",
       "       [0.75921981, 0.24078019],\n",
       "       [0.06467981, 0.93532019],\n",
       "       [0.14972084, 0.85027916]])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(Xtr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7571138211382114"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.predict(Xtr) == Ytr).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6920731707317073"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ytr.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \t I \t 5184 \t -0.16928512648504895\n",
      "1 \t . \t 5067 \t 0.7192804671012172\n",
      "2 \t and \t 2644 \t -0.4116934417186868\n",
      "3 \t , \t 2557 \t -0.0411241136152573\n",
      "4 \t the \t 2066 \t 0.012641508902283409\n",
      "5 \t to \t 1969 \t -0.5325539328969976\n",
      "6 \t ; \t 1764 \t 0.2599293016577009\n",
      "7 \t & \t 1739 \t 0.2179578748263298\n",
      "8 \t a \t 1684 \t 0.2920173413960011\n",
      "9 \t it \t 1563 \t -0.17777194862415419\n",
      "10 \t my \t 1538 \t -0.09634047179022644\n",
      "11 \t # \t 1521 \t 0.8596183070653756\n",
      "12 \t 039 \t 1516 \t -1.1186394636928518\n",
      "13 \t for \t 1199 \t -0.2818131758316536\n",
      "14 \t was \t 1057 \t -0.24145111806818936\n",
      "15 \t have \t 1033 \t 0.3531713062331918\n",
      "16 \t of \t 1003 \t 0.17328096159896428\n",
      "17 \t on \t 771 \t 0.23468611957493105\n",
      "18 \t in \t 728 \t 0.026270987104978882\n",
      "19 \t is \t 727 \t 0.7046297449280254\n",
      "20 \t me \t 723 \t -0.04203504468730681\n",
      "21 \t had \t 655 \t 0.12100361252422397\n",
      "22 \t with \t 650 \t 0.007246006634633771\n",
      "23 \t but \t 644 \t 0.3640540952397985\n",
      "24 \t this \t 640 \t -0.45200259066112974\n",
      "25 \t ! \t 639 \t 0.8249159977990878\n",
      "26 \t that \t 599 \t 0.2731913907805206\n",
      "27 \t t \t 524 \t -0.7048022892251979\n",
      "28 \t been \t 478 \t 0.15600403132179677\n",
      "29 \t so \t 466 \t 0.058952880484652644\n",
      "30 \t not \t 461 \t -0.6219464178596439\n",
      "31 \t am \t 390 \t 0.021006990305047657\n",
      "32 \t at \t 353 \t 0.06479390894234785\n",
      "33 \t as \t 349 \t 0.22147373561168354\n",
      "34 \t about \t 328 \t 0.6796551999848808\n",
      "35 \t side \t 325 \t 0.36703734672002125\n",
      "36 \t It \t 321 \t 0.15454309882990677\n",
      "37 \t day \t 319 \t 0.49351380517394183\n",
      "38 \t m \t 319 \t -0.4025168001800114\n",
      "39 \t taking \t 314 \t -0.061164830953636326\n",
      "40 \t after \t 309 \t 0.0710784454709131\n",
      "41 \t years \t 302 \t 0.8516129521887611\n",
      "42 \t no \t 299 \t -0.13589448414630545\n",
      "43 \t all \t 289 \t -0.07912110239203196\n",
      "44 \t ( \t 288 \t 0.8742527688567922\n",
      "45 \t s \t 287 \t -0.7950763425027414\n",
      "46 \t effects \t 284 \t -0.11647205447405908\n",
      "47 \t now \t 284 \t 0.2634118348480601\n",
      "48 \t pain \t 283 \t 0.12490523844587041\n",
      "49 \t ) \t 282 \t -0.60059121774811\n",
      "50 \t days \t 277 \t -0.15942962910732797\n",
      "51 \t ve \t 277 \t -0.2711361329049879\n",
      "52 \t has \t 267 \t 0.10689044210927719\n",
      "53 \t started \t 266 \t -0.15630600837707598\n",
      "54 \t first \t 262 \t 0.6104774177198959\n",
      "55 \t My \t 257 \t 0.15998795875498587\n",
      "56 \t get \t 257 \t -0.1395905463883539\n",
      "57 \t time \t 250 \t 0.038084843018538324\n",
      "58 \t The \t 248 \t -0.32066048279228265\n",
      "59 \t be \t 247 \t 0.3188306466736481\n",
      "60 \t out \t 238 \t -0.6923893083597499\n",
      "61 \t months \t 235 \t -0.6731504274737775\n",
      "62 \t take \t 233 \t 0.19340955316321096\n",
      "63 \t can \t 231 \t 0.5142926739478699\n",
      "64 \t or \t 228 \t 0.021469306471334593\n",
      "65 \t you \t 224 \t 0.6548196952346429\n",
      "66 \t up \t 223 \t 0.038798282539117004\n",
      "67 \t like \t 217 \t 0.02575721824445894\n",
      "68 \t only \t 216 \t 0.5255508703780214\n",
      "69 \t just \t 215 \t 0.020041179278337165\n",
      "70 \t from \t 209 \t 0.17189466221534555\n",
      "71 \t very \t 208 \t 0.22162510325795245\n",
      "72 \t feel \t 201 \t 0.1694113776145871\n",
      "73 \t would \t 201 \t 0.18040427761500577\n",
      "74 \t more \t 199 \t -0.07056135596455586\n",
      "75 \t 2 \t 195 \t -0.046059190642406454\n",
      "76 \t because \t 194 \t 0.004525837681932528\n",
      "77 \t are \t 193 \t 0.5469326706719849\n",
      "78 \t when \t 190 \t 0.3804160639752358\n",
      "79 \t back \t 190 \t -0.1317601523950321\n",
      "80 \t one \t 189 \t -0.026407085203656405\n",
      "81 \t week \t 185 \t -0.29923532513474194\n",
      "82 \t 3 \t 179 \t 0.28190352845050604\n",
      "83 \t period \t 173 \t 0.3548215996682753\n",
      "84 \t pill \t 168 \t -0.4531711526711092\n",
      "85 \t weeks \t 168 \t -0.3271421250153155\n",
      "86 \t medication \t 168 \t 0.020736740492887946\n",
      "87 \t took \t 166 \t -0.15200742999268158\n",
      "88 \t weight \t 166 \t 0.1988497553001934\n",
      "89 \t will \t 165 \t 0.0344882540519496\n",
      "90 \t if \t 163 \t 0.010287544577009824\n",
      "91 \t which \t 161 \t -0.12059132548896204\n",
      "92 \t life \t 160 \t 0.520571472219313\n",
      "93 \t got \t 159 \t 0.14243480208135237\n",
      "94 \t do \t 159 \t 0.046581833269798735\n",
      "95 \t bad \t 152 \t -0.5650300418468422\n",
      "96 \t This \t 150 \t -0.42326294802450765\n",
      "97 \t off \t 150 \t -0.5320811243488003\n",
      "98 \t doctor \t 149 \t -0.1175598833041161\n",
      "99 \t did \t 149 \t -0.16169846672259972\n"
     ]
    }
   ],
   "source": [
    "# Words in order of usage\n",
    "for i, word in enumerate(vocab):\n",
    "    print(i, '\\t', word, '\\t', vocab_counts[i][1], '\\t', model.coef_[0,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 \t 039 \t 1516 \t -1.1186394636928518\n",
      "45 \t s \t 287 \t -0.7950763425027414\n",
      "27 \t t \t 524 \t -0.7048022892251979\n",
      "60 \t out \t 238 \t -0.6923893083597499\n",
      "61 \t months \t 235 \t -0.6731504274737775\n",
      "30 \t not \t 461 \t -0.6219464178596439\n",
      "49 \t ) \t 282 \t -0.60059121774811\n",
      "95 \t bad \t 152 \t -0.5650300418468422\n",
      "5 \t to \t 1969 \t -0.5325539328969976\n",
      "97 \t off \t 150 \t -0.5320811243488003\n",
      "84 \t pill \t 168 \t -0.4531711526711092\n",
      "24 \t this \t 640 \t -0.45200259066112974\n",
      "96 \t This \t 150 \t -0.42326294802450765\n",
      "2 \t and \t 2644 \t -0.4116934417186868\n",
      "38 \t m \t 319 \t -0.4025168001800114\n",
      "85 \t weeks \t 168 \t -0.3271421250153155\n",
      "58 \t The \t 248 \t -0.32066048279228265\n",
      "81 \t week \t 185 \t -0.29923532513474194\n",
      "13 \t for \t 1199 \t -0.2818131758316536\n",
      "51 \t ve \t 277 \t -0.2711361329049879\n",
      "14 \t was \t 1057 \t -0.24145111806818936\n",
      "9 \t it \t 1563 \t -0.17777194862415419\n",
      "0 \t I \t 5184 \t -0.16928512648504895\n",
      "99 \t did \t 149 \t -0.16169846672259972\n",
      "50 \t days \t 277 \t -0.15942962910732797\n",
      "53 \t started \t 266 \t -0.15630600837707598\n",
      "87 \t took \t 166 \t -0.15200742999268158\n",
      "56 \t get \t 257 \t -0.1395905463883539\n",
      "42 \t no \t 299 \t -0.13589448414630545\n",
      "79 \t back \t 190 \t -0.1317601523950321\n",
      "91 \t which \t 161 \t -0.12059132548896204\n",
      "98 \t doctor \t 149 \t -0.1175598833041161\n",
      "46 \t effects \t 284 \t -0.11647205447405908\n",
      "10 \t my \t 1538 \t -0.09634047179022644\n",
      "43 \t all \t 289 \t -0.07912110239203196\n",
      "74 \t more \t 199 \t -0.07056135596455586\n",
      "39 \t taking \t 314 \t -0.061164830953636326\n",
      "75 \t 2 \t 195 \t -0.046059190642406454\n",
      "20 \t me \t 723 \t -0.04203504468730681\n",
      "3 \t , \t 2557 \t -0.0411241136152573\n",
      "80 \t one \t 189 \t -0.026407085203656405\n",
      "76 \t because \t 194 \t 0.004525837681932528\n",
      "22 \t with \t 650 \t 0.007246006634633771\n",
      "90 \t if \t 163 \t 0.010287544577009824\n",
      "4 \t the \t 2066 \t 0.012641508902283409\n",
      "69 \t just \t 215 \t 0.020041179278337165\n",
      "86 \t medication \t 168 \t 0.020736740492887946\n",
      "31 \t am \t 390 \t 0.021006990305047657\n",
      "64 \t or \t 228 \t 0.021469306471334593\n",
      "67 \t like \t 217 \t 0.02575721824445894\n",
      "18 \t in \t 728 \t 0.026270987104978882\n",
      "89 \t will \t 165 \t 0.0344882540519496\n",
      "57 \t time \t 250 \t 0.038084843018538324\n",
      "66 \t up \t 223 \t 0.038798282539117004\n",
      "94 \t do \t 159 \t 0.046581833269798735\n",
      "29 \t so \t 466 \t 0.058952880484652644\n",
      "32 \t at \t 353 \t 0.06479390894234785\n",
      "40 \t after \t 309 \t 0.0710784454709131\n",
      "52 \t has \t 267 \t 0.10689044210927719\n",
      "21 \t had \t 655 \t 0.12100361252422397\n",
      "48 \t pain \t 283 \t 0.12490523844587041\n",
      "93 \t got \t 159 \t 0.14243480208135237\n",
      "36 \t It \t 321 \t 0.15454309882990677\n",
      "28 \t been \t 478 \t 0.15600403132179677\n",
      "55 \t My \t 257 \t 0.15998795875498587\n",
      "72 \t feel \t 201 \t 0.1694113776145871\n",
      "70 \t from \t 209 \t 0.17189466221534555\n",
      "16 \t of \t 1003 \t 0.17328096159896428\n",
      "73 \t would \t 201 \t 0.18040427761500577\n",
      "62 \t take \t 233 \t 0.19340955316321096\n",
      "88 \t weight \t 166 \t 0.1988497553001934\n",
      "7 \t & \t 1739 \t 0.2179578748263298\n",
      "33 \t as \t 349 \t 0.22147373561168354\n",
      "71 \t very \t 208 \t 0.22162510325795245\n",
      "17 \t on \t 771 \t 0.23468611957493105\n",
      "6 \t ; \t 1764 \t 0.2599293016577009\n",
      "47 \t now \t 284 \t 0.2634118348480601\n",
      "26 \t that \t 599 \t 0.2731913907805206\n",
      "82 \t 3 \t 179 \t 0.28190352845050604\n",
      "8 \t a \t 1684 \t 0.2920173413960011\n",
      "59 \t be \t 247 \t 0.3188306466736481\n",
      "15 \t have \t 1033 \t 0.3531713062331918\n",
      "83 \t period \t 173 \t 0.3548215996682753\n",
      "23 \t but \t 644 \t 0.3640540952397985\n",
      "35 \t side \t 325 \t 0.36703734672002125\n",
      "78 \t when \t 190 \t 0.3804160639752358\n",
      "37 \t day \t 319 \t 0.49351380517394183\n",
      "63 \t can \t 231 \t 0.5142926739478699\n",
      "92 \t life \t 160 \t 0.520571472219313\n",
      "68 \t only \t 216 \t 0.5255508703780214\n",
      "77 \t are \t 193 \t 0.5469326706719849\n",
      "54 \t first \t 262 \t 0.6104774177198959\n",
      "65 \t you \t 224 \t 0.6548196952346429\n",
      "34 \t about \t 328 \t 0.6796551999848808\n",
      "19 \t is \t 727 \t 0.7046297449280254\n",
      "1 \t . \t 5067 \t 0.7192804671012172\n",
      "25 \t ! \t 639 \t 0.8249159977990878\n",
      "41 \t years \t 302 \t 0.8516129521887611\n",
      "11 \t # \t 1521 \t 0.8596183070653756\n",
      "44 \t ( \t 288 \t 0.8742527688567922\n"
     ]
    }
   ],
   "source": [
    "# Words in order of coefficient\n",
    "coef_order = np.argsort(model.coef_[0,:])\n",
    "for i in coef_order:\n",
    "    print(i, '\\t', vocab[i], '\\t', vocab_counts[i][1], '\\t', model.coef_[0,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
